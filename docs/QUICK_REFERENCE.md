# QUICK_REFERENCE.md
## AI Safety System - Architecture Cheat Sheet

---

## ğŸ“Š System Overview (One Diagram)

```
PLATFORMS (Discord, Twitch, Web)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EVENT INGESTION SERVICE (8001)         â”‚
â”‚  - Normalize webhooks                   â”‚
â”‚  - Deduplicate                          â”‚
â”‚  - Queue to Redis Streams               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            events:raw stream
                   â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ CRITICAL PATH       â”‚
        â”‚ (< 100ms SLO)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ RISK SCREENING (8002)      â”‚
    â”‚ - TinyBERT model           â”‚
    â”‚ - Rule-based checks        â”‚
    â”‚ - Returns risk score       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
        if risk > 0.7:
        events:reasoning_queue
             â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ASYNC PATH (< 5s latency, but not critical)         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ â”‚ EMBEDDING + CONTEXT (8003)           â”‚
             â”‚ â”‚ - Embed text â†’ OpenAI/ST              â”‚
             â”‚ â”‚ - Similarity search (Qdrant)          â”‚
             â”‚ â”‚ - Retrieve similar incidents          â”‚
             â”‚ â”‚ - Session aggregation                 â”‚
             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚            â†“
             â”‚      (similar_events + session_context)
             â”‚            â†“
             â””â”€â”€â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ REASONING (8004)               â”‚
                    â”‚ - LLM (OpenAI or local)        â”‚
                    â”‚ - Chain-of-thought             â”‚
                    â”‚ - Return action recommendation â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                    events:actions_pending
                             â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ ACTION EXECUTOR (8005)       â”‚
              â”‚ - Apply action (mute/timeout)â”‚
              â”‚ - Platform API integration   â”‚
              â”‚ - Audit logging              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ POSTGRES + REDIS + QDRANT    â”‚
              â”‚ - Audit trail                â”‚
              â”‚ - User violations            â”‚
              â”‚ - Vector embeddings          â”‚
              â”‚ - Cache + state              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ The 7 Services At A Glance

| Service | Port | Purpose | Input | Output | Tech |
|---------|------|---------|-------|--------|------|
| **Event Ingestion** | 8001 | Accept webhooks | HTTP POST | Redis events:raw | FastAPI |
| **Risk Screening** | 8002 | Classify risk (100ms) | Text | Risk score | ML model |
| **Embedding Context** | 8003 | Find similar patterns | Event ID | Similar events | Vector DB |
| **Reasoning** | 8004 | LLM analysis (RAG) | Risk + Context | Action recommendation | LLM |
| **Action Executor** | 8005 | Apply mitigation | Recommended action | Platform changes | SDK calls |
| **Session Manager** | 8006 | Track conversations | Events | Session state | Redis |
| **Reporting** | 8007 | Analytics & metrics | Events | Dashboard data | SQL queries |

---

## ğŸ”„ Event Flow Example

### Scenario: Harassment Detection & Mitigation

```
1. USER A writes: "You're trash at the game"
   â†’ Webhook sent to Event Ingestion Service
   
2. Event Ingestion
   â”œâ”€ Normalizes: {user_id, author_id, content, metadata}
   â”œâ”€ Deduplicates: Check if event_id seen before
   â””â”€ Publishes: â†’ events:raw stream
   
3. Risk Screening Service (consumer)
   â”œâ”€ Reads: event from events:raw
   â”œâ”€ ML Model inference: "harassment" score = 0.78
   â””â”€ Publishes: â†’ events:reasoning_queue (risk > 0.7 threshold)
   
4. Embedding Service (consumer)
   â”œâ”€ Generates embedding for "You're trash at the game"
   â”œâ”€ Searches Qdrant: Find similar past incidents
   â”œâ”€ Returns: [
   â”‚    {event_id: evt_2024_jan_10, similarity: 0.91, action: timeout_24h},
   â”‚    {event_id: evt_2024_jan_15, similarity: 0.87, action: warned}
   â”‚  ]
   â””â”€ Aggregates: Session data (12 msgs in 8 min, escalation_score: 0.76)
   
5. Reasoning Service (consumer)
   â”œâ”€ Prompts LLM: "Event: '{content}', Similar: [similar_events], History: [user history]"
   â”œâ”€ LLM Response: "Pattern matches 91% similar incident that resolved with 24h timeout. User has prior warning. Recommend: timeout_24h"
   â”œâ”€ Confidence: 0.88
   â””â”€ Publishes: â†’ events:actions_pending
   
6. Action Executor Service (consumer)
   â”œâ”€ Reads: Recommended action = timeout_24h
   â”œâ”€ Calls: Discord API â†’ Mute user for 24 hours
   â”œâ”€ Logs: Audit trail with evidence traces
   â”œâ”€ Publishes: â†’ events:actions_applied
   â””â”€ Stores: Action in PostgreSQL
   
7. Platform User Experience
   â””â”€ User A sees: "You've been timed out for 24 hours"
   
8. Session Manager
   â”œâ”€ Updates session: harassment_flags_count += 1
   â”œâ”€ Monitors: Escalation trend
   â””â”€ Alerts: If rapid escalation detected
```

---

## ğŸ“¦ Data Models (Key Fields)

### Event
```python
Event {
  event_id: str              # Unique ID
  platform: "discord"        # Where from
  user_id: str               # Target/recipient
  author_id: str             # Sender
  content: str               # Message text
  metadata: {
    timestamp: datetime
    user_reputation: 0.0-1.0
    author_reputation: 0.0-1.0
  }
}
```

### RiskPrediction
```python
RiskPrediction {
  event_id: str
  risk_score: 0.0-1.0        # ML confidence
  risk_category: "targeted_harassment"
  confidence: 0.0-1.0
  flags: ["repeated_name_calling", "targeting_behavior"]
  screening_time_ms: 45
}
```

### Action
```python
Action {
  action_id: str
  action_type: "timeout"     # warning|timeout|mute|ban
  duration_hours: 24
  user_id: str               # Who to punish
  platform: "discord"
  reason_code: "targeted_harassment"
  reasoning: "94% similar incident..."
  evidence_chain: [...]      # Traces of why
}
```

### Session
```python
Session {
  session_id: str
  participants: [user_id, ...]
  message_count: 12
  time_span_minutes: 8
  escalation_score: 0.76     # Temporal signal
  harassment_flags_count: 3
  temporal_features: {
    intervals: [45s, 30s, 25s],  # Time between messages
    risk_scores: [0.3, 0.5, 0.8] # Increasing!
  }
}
```

---

## ğŸ—„ï¸ Database Schema (Simplified)

### PostgreSQL
```sql
-- Users & Violations
users (id, user_id, platform, reputation, violation_count, ...)

-- Events Log
events (id, event_id, platform, content, risk_score, ...)

-- Sessions
sessions (id, session_id, channel_id, escalation_score, ...)

-- Actions Taken
actions (id, action_id, event_id, action_type, applied_at, ...)

-- Audit Trail
audit_log (id, action_id, actor, details, created_at, ...)
```

### Redis Streams
```
events:raw              # Raw incoming events
events:screened         # After risk screening
events:reasoning_queue  # Pending reasoning
events:actions_pending  # Pending execution
events:actions_applied  # Completed actions
events:dlq_errors       # Dead letter queue
```

### Redis Cache
```
embedding:{event_id} â†’ [0.123, -0.456, ...]  # 7 day TTL
user:reputation:{user_id} â†’ 0.75             # 1 hour TTL
session:{session_id} â†’ {...}                 # 30 min TTL
```

### Qdrant Vector DB
```
Collection: harassment_events
  Vector: 1536-dim (OpenAI embedding)
  Payload:
    - event_id
    - user_id
    - timestamp
    - risk_score
    - action_taken
    - action_outcome
```

---

## ğŸš€ Deployment Quick Commands

### Local (Docker Compose)
```bash
docker-compose up -d           # Start all services
docker-compose logs -f         # Follow logs
docker-compose ps              # Check status
docker-compose down -v         # Stop + delete volumes

# Test
curl -X POST http://localhost:8001/v1/events/ingest \
  -H "X-API-Key: test" \
  -H "Content-Type: application/json" \
  -d '{...}'
```

### Kubernetes (Helm)
```bash
helm install safety-system ./helm/safety-system \
  --namespace safety-system \
  --values ./helm/safety-system/values-prod.yaml

kubectl get pods -n safety-system
kubectl logs deployment/risk-screening -n safety-system -f
kubectl port-forward svc/prometheus 9090:9090 -n safety-system
```

---

## ğŸ“Š Key Metrics to Monitor

```
Latency:
  safety_screening_duration_ms{quantile="0.99"} < 100ms
  safety_reasoning_duration_ms{quantile="0.95"} < 5000ms

Throughput:
  rate(safety_events_processed_total[5m]) > 1000/sec

Queue Health:
  redis_stream_pending{stream="events:raw"} < 1000
  redis_stream_consumer_lag{group="reasoning"} < 5 sec

Accuracy:
  safety_false_positive_rate < 0.08
  histogram_quantile(0.5, safety_screening_confidence) > 0.8

Errors:
  rate(safety_action_failed_total[5m]) < 0.01
  rate(safety_llm_timeout_total[5m]) < 0.05
```

---

## ğŸ”§ Configuration Template (.env)

```bash
# Service Env
ENVIRONMENT=development
LOG_LEVEL=DEBUG

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis_password

# PostgreSQL
DATABASE_URL=postgresql+asyncpg://user:pass@postgres:5432/safety_db

# Qdrant
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_API_KEY=qdrant_key

# LLM
LLM_PROVIDER=local              # or "openai"
LOCAL_LLM_ENDPOINT=http://ollama:11434
OPENAI_API_KEY=sk-...

# ML Model
SCREENING_MODEL=tinybert
SCREENING_THRESHOLD=0.7

# Action Policy
ACTION_POLICY=graduated_escalation  # or "severity_based"

# Observability
OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
SENTRY_DSN=https://...

# Auth
JWT_SECRET=super_secret
API_KEYS=key1,key2,key3
```

---

## ğŸ¯ Extension Points (Plugin Architecture)

### 1. Add New Risk Model
```python
# services/risk-screening/src/risk_screening/models/
class CustomBERTModel(RiskClassifier):
    async def predict(self, text, context):
        # Your logic
        return RiskPrediction(...)

# Update config to use it
SCREENING_MODEL=custom_bert
```

### 2. Add New LLM Provider
```python
# services/reasoning/src/reasoning/llm/
class AnthropicProvider(LLMProvider):
    async def reason(self, prompt):
        # Claude API call
        return response

# Update config
LLM_PROVIDER=anthropic
```

### 3. Add New Action Policy
```python
# services/action-executor/src/action_executor/policies/
class ContextualPolicy(ActionPolicy):
    def recommend_action(self, context):
        # Custom logic based on user history, platform, etc.
        return Action(...)

# Update config
ACTION_POLICY=contextual
```

### 4. Add New Platform
```python
# services/event-ingestion/src/event_ingestion/connectors/
class RedditConnector(BasePlatformConnector):
    def normalize_event(self, webhook):
        # Reddit â†’ Event translation
        return Event(...)

# Update platform enum + connector registry
```

---

## ğŸ” Security Checklist

```
â–¡ X-API-Key validation on all webhooks
â–¡ JWT secret configured (services/shared/security/auth.py)
â–¡ Database passwords changed from defaults
â–¡ Redis password set
â–¡ TLS enabled on external endpoints
â–¡ Network policies restrict service access
â–¡ Secrets stored in vault (not in code)
â–¡ Input validation (Pydantic validators)
â–¡ Rate limiting configured
â–¡ Audit logging enabled
â–¡ PII redaction in logs
â–¡ Regular security scans (Trivy)
```

---

## ğŸ“ˆ Performance Tuning

```
# PostgreSQL
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB

# Redis
maxmemory = 4gb
maxmemory-policy allkeys-lru

# Python (Uvicorn)
workers = 4 * CPU_CORES
worker_class = uvicorn.workers.UvicornWorker

# Qdrant
vector_size = 1536 (match embedding model)
distance = "Cosine"
index_type = "Hnsw"
```

---

## ğŸ› Troubleshooting Reference

| Problem | Check | Solution |
|---------|-------|----------|
| Event not processing | Redis stream pending | `redis-cli XLEN events:raw` |
| High latency | Service CPU | `kubectl top pods` |
| Model inference slow | Cache hit rate | Check Redis key hits |
| LLM errors | API quota | Check OpenAI billing |
| Queue backlog | Consumer lag | Scale consumer replicas |
| Database slow | Connections | Check `pg_stat_activity` |
| Vector search slow | Qdrant index | Rebuild with HNSW |

---

## ğŸ“š File Navigation

```
SYSTEM_DESIGN.md
â”œâ”€ When: Understanding "why" architecture decisions
â”œâ”€ What: All components, contracts, data flow
â””â”€ How: Implementation patterns explained

MONOREPO_STRUCTURE.md
â”œâ”€ When: Planning code organization
â”œâ”€ What: Complete directory tree
â””â”€ How: File purposes explained

docker-compose.yml
â”œâ”€ When: Getting up running locally
â”œâ”€ What: All services + infrastructure
â””â”€ How: Ready to use, just run

shared_models.py
â”œâ”€ When: Understanding data contracts
â”œâ”€ What: Core Pydantic models
â””â”€ How: Copy to shared/safety_system/core/

event_ingestion_main.py
â”œâ”€ When: Implementing services
â”œâ”€ What: FastAPI service skeleton
â””â”€ How: Template for all services

DEPLOYMENT_GUIDE.md
â”œâ”€ When: Going to production
â”œâ”€ What: Step-by-step deployment
â””â”€ How: Local â†’ Staging â†’ Prod

IMPLEMENTATION_SUMMARY.md
â”œâ”€ When: Assessing project scope
â”œâ”€ What: Big picture + roadmap
â””â”€ How: Next steps + timeline

QUICK_REFERENCE.md (this file!)
â”œâ”€ When: You need a cheat sheet
â”œâ”€ What: Quick lookup of everything
â””â”€ How: Copy/paste ready templates
```

---

## â±ï¸ Time to Production

| Milestone | Effort | Time |
|-----------|--------|------|
| Local dev working | Easy | 1-2 hours |
| Screening service | Medium | 1-2 days |
| Full stack working | Medium | 3-5 days |
| Kubernetes deploy | Medium | 2-3 days |
| Production ready | Hard | 1-2 weeks |

**Critical Path**: Event Ingestion â†’ Screening â†’ Action Executor  
**Can Parallelize**: Embedding/Reasoning services can be added later

---

## ğŸ’¬ Key Terminology

| Term | Meaning |
|------|---------|
| **Harassment** | Temporal escalation pattern, not single incident |
| **Session** | Conversation thread (30-min TTL) |
| **Escalation Score** | Measure of increasing intensity over time |
| **Temporal Features** | Time-series characteristics (intervals, bursts) |
| **RAG** | Retrieve similar cases, Augment prompt, Generate answer |
| **Evidence Trace** | Why decision made (similar case, history, etc.) |
| **Graduated Action** | Warning â†’ Timeout â†’ Mute â†’ Ban |
| **Consumer Lag** | How behind a stream consumer is |
| **Event Replay** | Re-process events from Redis (for debugging) |

---

## ğŸ“ Learning Path

1. **Day 1**: Read SYSTEM_DESIGN.md sections 1-4 (understand harassment as temporal process)
2. **Day 2**: Read MONOREPO_STRUCTURE.md + run `docker-compose up`
3. **Day 3**: Deploy first service using event_ingestion_main.py template
4. **Day 4**: Integrate with your platform
5. **Day 5**: Load test and tune
6. **Week 2**: Go to Kubernetes
7. **Week 3+**: Integrate LLM + fine-tune models

**Expected outcome**: Production deployment in 3-4 weeks from start

---

**Last updated:** January 22, 2026  
**Status:** Production-ready specification  
**Next action:** `docker-compose up` ğŸš€
